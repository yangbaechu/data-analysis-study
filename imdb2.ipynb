{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. DownLoad Data\n",
    "\n",
    "http://ai.stanford.edu/~amaas/data/sentiment/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Unzip & Merge Data\n",
    "1. gunzip -c aclImdb_v1.tar.gz | tar xopf -\n",
    "2. cd aclImdb && mkdir movie_data\n",
    "3. for split in train test; do for sentiment in pos neg; do for file in $split/$sentiment/*; do cat $file >> movie_data/full_${split}.txt; echo >> movie_data/full_${split}.txt; done; done; done;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Read into Python "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_files\n",
    "path = './data/aclImdb/'\n",
    "names = ['neg', 'pos']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "def load_texts_labels_from_folders(path, folders):\n",
    "    texts,labels = [],[]\n",
    "    for idx,label in enumerate(folders):\n",
    "        for fname in glob.glob(os.path.join(path, label, '*.*')):\n",
    "            texts.append(open(fname, 'r').read())\n",
    "            labels.append(idx)\n",
    "    # stored as np.int8 to save space \n",
    "    return texts, np.array(labels).astype(np.int8)\n",
    "\n",
    "x_train,y_train = load_texts_labels_from_folders(f'{path}train',names)\n",
    "x_test, y_test = load_texts_labels_from_folders(f'{path}test',names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_Train_reviews: 25000 \n",
      "X_Test_reviews: 25000\n",
      "Y_Train_reviews: 25000 \n",
      "Y_Test_reviews: 25000\n"
     ]
    }
   ],
   "source": [
    "print('X_Train_reviews:',len(x_train),'\\nX_Test_reviews:', len(x_test))\n",
    "print('Y_Train_reviews:',len(y_train),'\\nY_Test_reviews:', len(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train[0] is Can you say \"All shock, no plot?\" There were so many unexplored directions in this movie. There was no history about the room other than the deaths. *WHY* was it evil? What made it that way? Why an \"hour\" countdown? Then, there were the unexplored things hinted at; for example we *saw* a camera in the air vent, which he mentioned. But when he climbed up said vent, there was no camera.<br /><br />How about the fact that all the ghosts looked \"Digital\", and things \"winked out\" before hitting the ground making a static noise? Hmmm... when you put all of *those* things together, it makes room 1408 look like a high-tech spook house. Except that there was no follow up on that.<br /><br />Oh... by the way... electronics don't work in 1408. Well, except for the TV... the cell phone has no signal, but Wireless Internet works fine. How many incontinuities can you possibly add? I'm sorry, but this film was nothing but \"shock after shock\". It's all been done before. Reflections in the mirror. Things just out of site. Changing paintings. Bleeding walls. The \"Oh, it was all just a dream... no it wasn't.\" And, if the room was \"evil\", why make our main character come to terms with his daughter's death, if it was going to keep him trapped there forever anyway? It just didn't make sense.<br /><br />Additionally, there was no background information about \"The first book\" that he wrote. Just some vague information about the \"dad was a jerk\" and so forth. Speaking of dads, what was with the bit about his father? \"You'll be in my place\".<br /><br />Overall, a truly HORRIBLE movie. It was 100% adrenalin shock factor, without any new or innovative effects, and certainly no back story, character development, etc.<br /><br />My overall impression is that the entire movie was made on the \"Cheap\"; pretty much using one set and a couple of location shots, and was nothing but an effects film of recycled, cheesy, \"seen-that-before\" effects. \n",
      "\n",
      "y_train[0] is 0\n"
     ]
    }
   ],
   "source": [
    "print('X_train[0] is',x_train[0],'\\n\\ny_train[0] is',y_train[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Clean and Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size: 129549\n",
      "X_train:\n",
      "<25000x129549 sparse matrix of type '<class 'numpy.int64'>'\n",
      "\twith 3607330 stored elements in Compressed Sparse Row format>\n",
      "X_test: \n",
      "<25000x129549 sparse matrix of type '<class 'numpy.int64'>'\n",
      "\twith 3392376 stored elements in Compressed Sparse Row format>\n",
      "Number of features: 129549\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "\"\"\"\n",
    "1. min_df ( = 5): defines the minimum frequency of a word for it to be counted as a feature\n",
    "2. ngram_range (= (2,2)): The ngram_range parameter is a tuple. \n",
    "   It defines the minimum and maximum length of sequence of tokens considered. \n",
    "   In this case, this length is 2. So, this will find sequence of 2 tokens like\n",
    "   — ‘but the’, ‘wise man’ etc.\n",
    "\"\"\"\n",
    "cv = CountVectorizer(min_df=5, ngram_range=(2,2))\n",
    "X_train = cv.fit(x_train).transform(x_train)\n",
    "X_test = cv.transform(x_test)\n",
    "\n",
    "print(\"Vocabulary size: {}\".format(len(cv.vocabulary_)))\n",
    "print(\"X_train:\\n{}\".format(repr(X_train)))\n",
    "print(\"X_test: \\n{}\".format(repr(X_test)))\n",
    "\n",
    "feature_names = cv.get_feature_names()\n",
    "print(\"Number of features: {}\".format(len(feature_names)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Test Validation Split for model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape X_train : (18750, 129549) \n",
      "Shape y_train: 18750 \n",
      "Shape X_val: (6250, 129549) \n",
      "Shape y_val: 6250 \n",
      "Shape X_test: (25000, 129549) \n",
      "Shape y_test: 25000\n"
     ]
    }
   ],
   "source": [
    "# Data Split\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    train_size = 0.75\n",
    ")\n",
    "print('Shape X_train :',X_train.shape,\n",
    "     '\\nShape y_train:', len(y_train),\n",
    "     '\\nShape X_val:', X_val.shape,\n",
    "     '\\nShape y_val:', len(y_val),\n",
    "     '\\nShape X_test:', X_test.shape,\n",
    "     '\\nShape y_test:', len(y_test),)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import statsmodels.api as sm\n",
    "\n",
    "results = dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for depth = 100: 0.668\n",
      "Accuracy for depth = 150: 0.66992\n",
      "Accuracy for depth = 200: 0.67408\n",
      "Accuracy for depth = 250: 0.67376\n",
      "Accuracy for depth = 300: 0.67008\n",
      "\n",
      "\n",
      "Best_acc = 0.67408\n",
      "Best_depth = 200\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "        \n",
    "max_depth  = [100, 150, 200, 250, 300]\n",
    "best_acc = 0\n",
    "best_depth = 0\n",
    "dt_models = list()\n",
    "for depth in max_depth: \n",
    "\n",
    "    dt = DecisionTreeClassifier(random_state=0,\n",
    "                                max_depth=depth)\n",
    "    dt.fit(X_train, y_train)\n",
    "    \n",
    "    dt_models.append(dt)\n",
    "    \n",
    "    acc = accuracy_score(y_val, dt.predict(X_val))\n",
    "    \n",
    "    print(\"Accuracy for depth = %s: %s\"\n",
    "         % (depth, acc ))\n",
    "    \n",
    "    if best_acc < acc:\n",
    "        best_acc = acc\n",
    "        best_depth = depth\n",
    "    \n",
    "    \n",
    "print('\\n\\nBest_acc = {}\\nBest_depth = {}'.format(best_acc, best_depth))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Test Accuracy: 0.68336\n"
     ]
    }
   ],
   "source": [
    "final_model = dt_models[2]\n",
    "final_pred = final_model.predict(X_test)\n",
    "final_acc = accuracy_score(y_test, final_pred)\n",
    "print(\"Final Test Accuracy: %s\"\n",
    "     %final_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best top 5\n",
      "('the worst', 0.053830324893383935)\n",
      "('waste of', 0.02059355860242169)\n",
      "('the best', 0.019957900106621684)\n",
      "('supposed to', 0.013725182694132337)\n",
      "('so bad', 0.01297227158613104)\n",
      "\n",
      "\n",
      "Best bottom 5\n",
      "('00 and', 0.0)\n",
      "('00 in', 0.0)\n",
      "('000 00', 0.0)\n",
      "('000 000', 0.0)\n",
      "('000 and', 0.0)\n"
     ]
    }
   ],
   "source": [
    "feature_to_coef = {\n",
    "    word: coef for word, coef in zip(\n",
    "        cv.get_feature_names(), final_model.feature_importances_\n",
    "    )\n",
    "}\n",
    "print(\"Best top 5\")\n",
    "for best_pos in sorted(\n",
    "    feature_to_coef.items(),\n",
    "    key = lambda x: x[1],\n",
    "    reverse=True)[:5]:\n",
    "    print(best_pos)\n",
    "    \n",
    "print(\"\\n\\nBest bottom 5\")    \n",
    "for best_neg in sorted(\n",
    "    feature_to_coef.items(),\n",
    "    key = lambda x: x[1])[:5]:\n",
    "    print(best_neg)\n",
    "    \n",
    "results['DT']=final_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for estimator = 100: 0.81648\n",
      "Accuracy for estimator = 110: 0.81792\n",
      "Accuracy for estimator = 120: 0.81696\n",
      "Accuracy for estimator = 130: 0.81824\n",
      "Accuracy for estimator = 140: 0.8176\n",
      "\n",
      "\n",
      "Best_acc = 0.81824\n",
      "Best_est = 130\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "n_estimators  = [100, 110, 120, 130, 140]\n",
    "best_acc = 0\n",
    "best_est = 0\n",
    "rf_models = list()\n",
    "\n",
    "for est in n_estimators: \n",
    "\n",
    "    rf = RandomForestClassifier(random_state=0,\n",
    "                                n_estimators=est)\n",
    "    rf.fit(X_train, y_train)\n",
    "    \n",
    "    rf_models.append(rf)\n",
    "    \n",
    "    acc = accuracy_score(y_val, rf.predict(X_val))\n",
    "    \n",
    "    print(\"Accuracy for estimator = %s: %s\"\n",
    "         % (est, acc ))\n",
    "    \n",
    "    if best_acc < acc:\n",
    "        best_acc = acc\n",
    "        best_est = est\n",
    "    \n",
    "    \n",
    "print('\\n\\nBest_acc = {}\\nBest_est = {}'.format(best_acc, best_est))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Accuracy: 0.82736\n"
     ]
    }
   ],
   "source": [
    "final_model = rf_models[3]\n",
    "final_pred = final_model.predict(X_test)\n",
    "final_acc = accuracy_score(y_test, final_pred)\n",
    "print(\"Final Accuracy: %s\"\n",
    "     %final_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best top 5\n",
      "('the worst', 0.009510385783819452)\n",
      "('waste of', 0.003330698707017902)\n",
      "('the best', 0.0032582765138193114)\n",
      "('is great', 0.0023921802910388265)\n",
      "('not even', 0.0020064839570563286)\n",
      "\n",
      "\n",
      "Best bottom 5\n",
      "('00 and', 0.0)\n",
      "('000 00', 0.0)\n",
      "('000 the', 0.0)\n",
      "('10 30', 0.0)\n",
      "('10 favorite', 0.0)\n"
     ]
    }
   ],
   "source": [
    "feature_to_coef = {\n",
    "    word: coef for word, coef in zip(\n",
    "        cv.get_feature_names(), final_model.feature_importances_\n",
    "    )\n",
    "}\n",
    "print(\"Best top 5\")\n",
    "for best_pos in sorted(\n",
    "    feature_to_coef.items(),\n",
    "    key = lambda x: x[1],\n",
    "    reverse=True)[:5]:\n",
    "    print(best_pos)\n",
    "    \n",
    "print(\"\\n\\nBest bottom 5\")    \n",
    "for best_neg in sorted(\n",
    "    feature_to_coef.items(),\n",
    "    key = lambda x: x[1])[:5]:\n",
    "    print(best_neg)\n",
    "    \n",
    "results['RF'] = best_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for C = 0.01: 0.8544\n",
      "Accuracy for C = 0.05: 0.86688\n",
      "Accuracy for C = 0.25: 0.87088\n",
      "Accuracy for C = 0.5: 0.8704\n",
      "Accuracy for C = 1: 0.87024\n",
      "\n",
      "\n",
      "Best_acc = 0.87088\n",
      "Best_c = 0.25\n"
     ]
    }
   ],
   "source": [
    "# Train Model\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\"\"\"C : float, optional (default=1.0)\n",
    "    Inverse of regularization strength; must be a positive float.\n",
    "    Like in support vector machines, smaller values specify stronger\n",
    "    regularization.\"\"\"\n",
    "\n",
    "Cs = [0.01, 0.05, 0.25, 0.5, 1]\n",
    "best_acc = 0\n",
    "best_c = 0\n",
    "lr_models = list()\n",
    "for c in Cs:\n",
    "    \n",
    "    lr = LogisticRegression(random_state=0,\n",
    "                            C=c)\n",
    "    \n",
    "    lr.fit(X_train, y_train)\n",
    "    \n",
    "    lr_models.append(lr)\n",
    "    \n",
    "    acc = accuracy_score(y_val, lr.predict(X_val))\n",
    "    \n",
    "    print(\"Accuracy for C = %s: %s\"\n",
    "         % (c, acc ))\n",
    "    \n",
    "    if best_acc < acc:\n",
    "        best_acc = acc\n",
    "        best_c = c\n",
    "        \n",
    "print('\\n\\nBest_acc = {}\\nBest_c = {}'.format(best_acc, best_c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Test Accuracy: 0.87132\n"
     ]
    }
   ],
   "source": [
    "final_model = lr_models[2]\n",
    "final_pred = final_model.predict(X_test)\n",
    "final_acc = accuracy_score(y_test, final_pred)\n",
    "print(\"Final Test Accuracy: %s\"\n",
    "     %final_acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Positive top 5\n",
      "('highly recommended', 0.8281449117175549)\n",
      "('must see', 0.8265123956042405)\n",
      "('loved this', 0.8192495822676402)\n",
      "('well worth', 0.8090599754396214)\n",
      "('the best', 0.8077293043329935)\n",
      "\n",
      "\n",
      "Best Negative top 5\n",
      "('the worst', -1.8375164527936623)\n",
      "('waste of', -1.2611037925613702)\n",
      "('than this', -0.9993017694507464)\n",
      "('not worth', -0.821529240199869)\n",
      "('at best', -0.808505413291275)\n"
     ]
    }
   ],
   "source": [
    "feature_to_coef = {\n",
    "    word: coef for word, coef in zip(\n",
    "        cv.get_feature_names(), final_model.coef_[0]\n",
    "    )\n",
    "}\n",
    "print(\"Best Positive top 5\")\n",
    "for best_pos in sorted(\n",
    "    feature_to_coef.items(),\n",
    "    key = lambda x: x[1],\n",
    "    reverse=True)[:5]:\n",
    "    print(best_pos)\n",
    "    \n",
    "print(\"\\n\\nBest Negative top 5\")    \n",
    "for best_neg in sorted(\n",
    "    feature_to_coef.items(),\n",
    "    key = lambda x: x[1])[:5]:\n",
    "    print(best_neg)\n",
    "    \n",
    "results['LR'] = best_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Result of the experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The results of three model are\n",
      " {'DT': 0.68336, 'RF': 0.81824, 'LR': 0.87088}\n"
     ]
    }
   ],
   "source": [
    "print(\"The results of three model are\\n\", results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "결과적으로 Logistic Regression이 가장 분류를 잘 한다.\n",
    "따라서 Logistic Regression이 imdb review sentimental analysis\n",
    "가장 적합한 model이다.\n",
    "\"\"\"\n",
    "model = lr_models[2]\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "conf = confusion_matrix(y_test, y_pred)\n",
    "report = classification_report(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "intercept: [0.09919626]\n",
      "\n",
      "coef: [[-0.04784019 -0.01366857  0.01087227 ...  0.04161188  0.03742215\n",
      "   0.02525922]]\n",
      "\n",
      "len of coef: 129549\n",
      "\n",
      "Confusion Matrix\n",
      "\n",
      " [[10755  1745]\n",
      " [ 1472 11028]]\n",
      "\n",
      "\n",
      "Classification Report\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.86      0.87     12500\n",
      "           1       0.86      0.88      0.87     12500\n",
      "\n",
      "    accuracy                           0.87     25000\n",
      "   macro avg       0.87      0.87      0.87     25000\n",
      "weighted avg       0.87      0.87      0.87     25000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('\\nintercept:', model.intercept_)\n",
    "print('\\ncoef:', model.coef_)\n",
    "print('\\nlen of coef:', len(model.coef_[0]))\n",
    "print(\"\\nConfusion Matrix\\n\\n\", conf)\n",
    "print(\"\\n\\nClassification Report\\n\\n\", report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8,8))\n",
    "ax.imshow(conf)\n",
    "ax.grid(False)\n",
    "ax.set_xlabel('Predicted outputs', color='black')\n",
    "ax.set_ylabel('Actual outputs', color='black')\n",
    "for i in range(2):\n",
    "    for j in range(2):\n",
    "        ax.text(j, i, conf[i, j], ha='center', va='center', color='black')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "[env1]",
   "language": "python",
   "name": "env1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
